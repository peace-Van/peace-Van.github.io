---
layout: post
title: A neural network approach for climate classification - Sec 2. Vegetation mapping result and discussion
author: Van
category: climate
---

[Sec 1.](https://peace-van.github.io/climate/2023/11/08/sec1.html) introduced the methodology of NN learning of vegetation mapping, mainly the dataset and the NN structure. This article will focus on the result and some insights from it.  

## Training

![train](/assets/NN2/train.png)  
The training progress plot. Right-click for full image.   

The network was trained over 20 epochs using the *Adam* solver. The batch size was 256. Learning rate started at 0.001 and reduced to 0.0001 after 10 epochs. The validation set was the entire training set, and validation was done at the end of each epoch.    

> The training would be several times faster if we use PyTorch/Tensorflow as the DL software, which is also more commonly used. The problem is that, unfortunately, for the next step of clustering, currently there's no Python package that supports high dimensional (3D or over) self-organizing maps. For the sake of integrity, the project uses Matlab (R2020b or above will work) from start to end.   

## NN parameters

In this part I will discuss the parameters that are interpretable.

### Custom activation layer

As discussed in Sec 1, this layer simulates the empirical comparison against thresholds. The training result shows most of the thresholds did not move far away from Köppen's estimation. A notable observation is that $\sigma_{p_i}$ significantly increase with higher precipitation level $i$. This means that the network learned that overabundant precipitation rarely affect the vegetation so it deemed weaker discriminatory power on higher precipitation.

| Parameter      | Initial value | Learned value |
|----------------|---------------|---------------|
| $\mu_{t_1}$    | -18           | -16.9         |
| $\mu_{t_2}$    | 0             | 0.6           |
| $\mu_{t_3}$    | 10            | 10.7          |
| $\mu_{t_4}$    | 22            | 25.3          |
| $\sigma_t$     | 4             | 4.5           |
| $\mu_{p_1}$    | 10            | 7.7           |
| $\mu_{p_2}$    | 40            | 37.2          |
| $\mu_{p_3}$    | 100           | 105.7         |
| $\sigma_{p_1}$ | 10            | 10.0          |
| $\sigma_{p_2}$ | 20            | 27.1          |
| $\sigma_{p_3}$ | 30            | 59.2          |

### `fc-2` layer

This is the last layer before output that has learnable parameters. Each output neuron of this layer corresponds to a land cover type. It can be seen that predictions for *deciduous needleleaf forest*, *closed shrubland* and *permanent wetland* were severely suppressed by this layer. These types are relatively rare around the world. The bias parameters do not interact with the input climate data in forward propagation and thus can be seen in an average sense as indicators of impact from factors other than climate on land cover. The potential natural vegetation ([Tomislav Hengl et al. 2018](https://pubmed.ncbi.nlm.nih.gov/30155360/)) may be obtained by setting these parameters to zero and then passing climate data again through the trained network, which is another topic for future exploration.

| Land cover type             | Cover percentage | Learned bias |
|-----------------------------|------------------|--------------|
| evergreen needleleaf forest | 2.32%            | -0.19        |
| deciduous needleleaf forest | 0.32%            | -1.67        |
| evergreen broadleaf forest  | 6.94%            | 0.88         |
| deciduous broadleaf forest  | 1.95%            | -0.47        |
| mixed forest                | 3.94%            | 0.27         |
| closed shrubland            | 0.31%            | -1.63        |
| open shrubland              | 10.54%           | 0.31         |
| woody savanna               | 8.97%            | 0.18         |
| savanna                     | 11.29%           | 0.15         |
| grassland                   | 22.38%           | 0.09         |
| permanent wetland           | 3.87%            | -1.60        |
| cropland mosaics            | 8.58%            | 0.24         |
| snow and ice                | 4.98%            | -0.30        |
| barren                      | 13.62%           | -0.28        |

> The cover percentage in the table is based on the land cover dataset of the year 2021.

## Land cover classification

The task that the neural network accomplished is to classify the climate normal data according to their underlying land cover conditions. It's basically a multi-label classification problem. Meanwhile we hope it utilizes more information than just the label with the highest percentage (*predominant land cover type*), so we use the binary cross-entropy loss, expecting the NN to output the correct percentages. 

In this part we reduce the problem to multi-label classification. If we see the correct label as the one with the highest percentage on the land pixel, how is the network's performance and accuracy?

> The figures are all based on the land cover dataset of the year 2021. 

![p1](/assets/NN2/true_veg.png)
Prediction target. Color each $0.5° \times  0.5°$ land pixel with its predominant land cover type, and we get the world map of land cover. Right-click for full image.   

![p2](/assets/NN2/pred_veg.png)
Prediction output. A smoothed version of the ground truth. Right-click for full image.  

![p3](/assets/NN2/legend.png)
<p align="center">
  Color scheme
</p>

![p4](/assets/NN2/veg_conf.png)
Confusion chart. Right-click for full image.   

From the confusion chart it can be seen that the network accurately identified land cover types such as *barren* and *ice* which are marked by pronounced climate features. Types that are underrepresented or have no clear climate features, such as *closed shrubland* and *permanent wetland*, are challenging for the network (as well as humans). The prediction achieved an overall accuracy of 82.84%. The [Kappa statistic](https://www.sciencedirect.com/science/article/pii/030438009290003W) $\kappa$ is 0.8036, indicating very good agreement between real-world data and the prediction. The accuracy can be bounded by the problem’s nature: land cover is the result of multiple factors, including but not limited to climate, terrain topology and human activities. Accurate prediction of a region’s land cover merely by the local climate may imply overfitting.

## Climate features

![p5](/assets/NN2/feature1-Damp-coldness.png)
![p6](/assets/NN2/feature2-Continentality.png)
![p7](/assets/NN2/feature3-Growing Season.png)
Three principle climate features extracted by the network. Brighter regions represent higher values. From top to bottom, feature 1, explaining 36.34% of information, implies **damp-coldness**. Feature 2, explaining 16.67%, can be regarded as **continentality**. Feature 3, explaining 14.29%, indicates the **seasonal contrast** in growth capability. The explained variance of the fourth feature significantly drops to 6.56%, so we are not going to analyze it further.    

> Continentality basically represents aridity. For two observations with similar aridity, the one with colder temperature has a higher value.

> Köppen's measurement for continentality is indirect and unclear. He used summer temperature as a criterion for the **a, b, c** subtype, where a moderate summer (**b** or **c** subtype) indicates oceanic characteristics. He even used a **d** subtype according to winter temperature to mark the extreme continentality in Eastern Siberia. Also, the main group **D** was originally named the `continental` group by Köppen, though nowadays many climatologists don't prefer this term and instead call it the `cold` group. Our data science method tells us the intricacies of continentality.   

> The first feature which I call it damp-coldness basically represents temperature level. For two observations with similar temperature, the one with less aridity has a higher value. Hopefully someone could give this feature a better name.

> **Warmth is naturally linked with dryness by causing higher evaporation.** In view of this fact, temperature level and aridity are not independent, while principle components are required to be independent. PCA on the learned climate features defines this new climate term (the first feature) for us - **the orthogonal counterpart of continentality**. These two features form the orthogonal basis on the temperature-precipitation/aridity plane.

> The third feature, seasonality, represents the starkness of growing season. For example, the savanna climate has a high value of this feature due to its distinct dry-wet season pattern. The rainforest climate has a low value because the condition is almost stable all year round. Comparing with an icecap or hot desert climate which also has no seasonal variations, the rainforest climate has a higher value because its growing condition is obviously better.

> Although related to precipitation pattern, this seasonality feature derived by us is different from Köppen's classification criterion for the **f, w, s** subtypes. The growing condition is comprehensively considered rather than the empirical precipitation concentration in the so-called summer/winter. That explains why in our climate classification scheme the Mediterranean characteristic is not pronounced, as you can see later.  

Climate features were extracted by propagating the climate normal dataset through the trained network and then retrieving the activations of the `concat` layer. The `concat` layer derives 512 climate features for clustering. It is not feasible to analyze them one by one, so principle component analysis (PCA) was applied first. Out of the 512 components after PCA, 15 components explained over 90% of the information. The most prominent three components on the 1991-2020 climate normals dataset are plotted and explained above. With the decreasing proportion of information explained, the climatological or biophysiological meanings of the features become more obscure and harder to interpret. Still from the three illustrated, we can see that the network did learn a lot of informative features that indicate the underlying land cover conditions.

The next section will talk about a direct clustering on the 15 principle climate features and derivation of our first simple climate classification (clustering in terms of data science) scheme. We will have a more complicated one later.   
